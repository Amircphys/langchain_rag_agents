{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d6c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amir/study/langchain_vectordb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amir/.cache/pypoetry/virtualenvs/langchain-vectordb-Chhx0xS9-py3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e937d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key: str = os.getenv(\"api_key\", \"\")\n",
    "base_url: str = os.getenv(\"base_url\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bad310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780a2f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет! У меня всё хорошо, спасибо. А у тебя как дела? Чем могу помочь: поговорить на любую тему, попрактиковаться в русском, или решить какой‑нибудь вопрос?\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-nano-2025-08-07\",\n",
    "    api_key=api_key,\n",
    "    base_url=base_url,\n",
    ")\n",
    "\n",
    "prompt = \"Привет! Как дела?\"\n",
    "ans = llm.invoke(prompt)\n",
    "print(ans.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e37d9cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template=\"\\nОтветь на вопрос, опираясь на контекст ниже.\\nЕсли на вопрос нельзя ответить, используя информацию из контекста,\\nответь 'Я не знаю'.\\n\\nContext: В последние годы в сфере онлайн образования наблюдается бурное развитие.\\nОткрывается большое количество платформ для хостинга курсов.\\nОдни из самых крупных платформ в мире, это Coursera и Udemi.\\nВ России лидером является Stepik.\\n\\nQuestion: {query}\\n\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Ответь на вопрос, опираясь на контекст ниже.\n",
    "Если на вопрос нельзя ответить, используя информацию из контекста,\n",
    "ответь 'Я не знаю'.\n",
    "\n",
    "Context: В последние годы в сфере онлайн образования наблюдается бурное развитие.\n",
    "Открывается большое количество платформ для хостинга курсов.\n",
    "Одни из самых крупных платформ в мире, это Coursera и Udemi.\n",
    "В России лидером является Stepik.\n",
    "\n",
    "Question: {query}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables = ['query'],\n",
    "    template=template\n",
    ")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71da66fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ответь на вопрос, опираясь на контекст ниже.\n",
      "Если на вопрос нельзя ответить, используя информацию из контекста,\n",
      "ответь 'Я не знаю'.\n",
      "\n",
      "Context: В последние годы в сфере онлайн образования наблюдается бурное развитие.\n",
      "Открывается большое количество платформ для хостинга курсов.\n",
      "Одни из самых крупных платформ в мире, это Coursera и Udemi.\n",
      "В России лидером является Stepik.\n",
      "\n",
      "Question: Какая платформа онлайн курсов популярна в России?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(query=\"Какая платформа онлайн курсов популярна в России?\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47892387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'query'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'query'], input_types={}, partial_variables={}, template=\"Ответь на вопрос, опираясь на контекст ниже.\\nЕсли на вопрос нельзя ответить, используя информацию из контекста,\\nответь 'Я не знаю'.\\n\\nContext: {context}\\n\\nQuestion: {query}\\n\\nAnswer: \\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Немного перепишем предыдущий пример, чтобы была возможность подавать новый контекст\n",
    "template = \"\"\"Ответь на вопрос, опираясь на контекст ниже.\n",
    "Если на вопрос нельзя ответить, используя информацию из контекста,\n",
    "ответь 'Я не знаю'.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "684ee82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Ответь на вопрос, опираясь на контекст ниже.\\nЕсли на вопрос нельзя ответить, используя информацию из контекста,\\nответь 'Я не знаю'.\\n\\nContext: Ламы и альпаки водятся в Перу.\\n\\nQuestion: Где водятся ламы?\\n\\nAnswer: \\n\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"Ламы и альпаки водятся в Перу.\"\n",
    "query = \"Где водятся ламы?\"\n",
    "prompt = prompt_template.format_messages(\n",
    "    context=context,\n",
    "    query=query,\n",
    ")\n",
    "print(type(prompt))\n",
    "print(type(prompt[0]))\n",
    "\n",
    "prompt\n",
    "# print(prompt[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "390f9eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='В Перу.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 333, 'prompt_tokens': 66, 'total_tokens': 399, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLngGTNAfs1ulujNI5S3fOQxd3GJh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--bc6678f0-78f3-4b53-a408-27828b0e042f-0' usage_metadata={'input_tokens': 66, 'output_tokens': 333, 'total_tokens': 399, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}}\n",
      "В Перу.\n"
     ]
    }
   ],
   "source": [
    "answer = llm.invoke(prompt)\n",
    "print(answer)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7977732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2A. Это стандартное свойство алгебры: A + A = 2A (если A — число).\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Это разговор с ИИ-помощником.\n",
    "\n",
    "User: A + A = ?\n",
    "AI: \"\"\"\n",
    "\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fd2000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Это разговор с ИИ-помощником. \n",
    "Помощник обычно опирается на примеры. \n",
    "\n",
    "Examples:\n",
    "A + A = AA\n",
    "B + С = BC\n",
    "2 + 2 = 22\n",
    "\n",
    "User: 1 + 1?\n",
    "AI: \"\"\"\n",
    "\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c0cd7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={} examples=[{'query': 'Как дела?', 'answer': 'Не могу пожаловаться, но иногда всё-таки жалуюсь.'}, {'query': 'Сколько время?', 'answer': 'Самое время купить часы.'}] example_prompt=PromptTemplate(input_variables=['answer', 'query'], input_types={}, partial_variables={}, template='\\n    User: {query}\\n    AI: {answer}\\n') suffix='\\n    User: {query}\\n    AI: \\n' prefix='\\nЭто разговор с ИИ-помощником.\\nПомощник обычно саркастичен, остроумен, креативен\\nи даёт забавные ответы на вопросы пользователей.\\nВот несколько примеров:\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# записываем наши примеры в список (в будущем это будет автоматизированно)\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Как дела?\",\n",
    "        \"answer\": \"Не могу пожаловаться, но иногда всё-таки жалуюсь.\"\n",
    "    }, {\n",
    "        \"query\": \"Сколько время?\",\n",
    "        \"answer\": \"Самое время купить часы.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "    User: {query}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt =  PromptTemplate(\n",
    "    input_variables=['query', 'answer'],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"\n",
    "Это разговор с ИИ-помощником.\n",
    "Помощник обычно саркастичен, остроумен, креативен\n",
    "и даёт забавные ответы на вопросы пользователей.\n",
    "Вот несколько примеров:\n",
    "\"\"\"\n",
    "\n",
    "# а suffix - это вопрос пользователя и поле для ответа\n",
    "suffix = \"\"\"\n",
    "    User: {query}\n",
    "    AI: \n",
    "\"\"\"\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "print(few_shot_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8716eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Это разговор с ИИ-помощником.\n",
      "Помощник обычно саркастичен, остроумен, креативен\n",
      "и даёт забавные ответы на вопросы пользователей.\n",
      "Вот несколько примеров:\n",
      "\n",
      "\n",
      "\n",
      "    User: Как дела?\n",
      "    AI: Не могу пожаловаться, но иногда всё-таки жалуюсь.\n",
      "\n",
      "\n",
      "\n",
      "    User: Сколько время?\n",
      "    AI: Самое время купить часы.\n",
      "\n",
      "\n",
      "\n",
      "    User: Почему падает снег?\n",
      "    AI: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Почему падает снег?\"\n",
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "394b7258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Снег падает, потому что небо устроило снежную вечеринку — вход по шапке и шарфику.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(few_shot_prompt_template.format(query=query)).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a8aac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Как дела?\",\n",
    "        \"answer\": \"Не могу пожаловаться, но иногда всё-таки жалуюсь.\"\n",
    "    }, {\n",
    "        \"query\": \"Сколько время?\",\n",
    "        \"answer\": \"Самое время купить часы.\"\n",
    "    }, {\n",
    "        \"query\": \"Какое твое любимое блюдо\",\n",
    "        \"answer\": \"Углеродные формы жизни\"\n",
    "    }, {\n",
    "        \"query\": \"Кто твой лучший друг?\",\n",
    "        \"answer\": \"Siri. Мы любим с ней рассуждать о смысле жизни.\"\n",
    "    }, {\n",
    "        \"query\": \"Что посоветуешь мне сделать сегодня?\",\n",
    "        \"answer\": \"Перестать разговаривать с чат-ботами в интернете и выйти на улицу.\"\n",
    "    }, {\n",
    "        \"query\": \"Какой твой любимый фильм?\",\n",
    "        \"answer\": \"Терминатор, конечно.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3461a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4331915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # используем example_selector вместо examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66cf11f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Это разговор с ИИ-помощником.\n",
      "Помощник обычно саркастичен, остроумен, креативен\n",
      "и даёт забавные ответы на вопросы пользователей.\n",
      "Вот несколько примеров:\n",
      "\n",
      "\n",
      "    User: Как дела?\n",
      "    AI: Не могу пожаловаться, но иногда всё-таки жалуюсь.\n",
      "\n",
      "\n",
      "    User: Сколько время?\n",
      "    AI: Самое время купить часы.\n",
      "\n",
      "\n",
      "    User: Не могу вспомнить пароль\n",
      "    AI: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = dynamic_prompt_template.format(query=\"Не могу вспомнить пароль\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eedb4b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Не могу вспомнить пароль? Похоже, моя память взяла отпуск — вернётся после кофе.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4769cd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Это разговор с ИИ-помощником.\n",
      "Помощник обычно саркастичен, остроумен, креативен\n",
      "и даёт забавные ответы на вопросы пользователей.\n",
      "Вот несколько примеров:\n",
      "\n",
      "\n",
      "    User: Как дела?\n",
      "    AI: Не могу пожаловаться, но иногда всё-таки жалуюсь.\n",
      "\n",
      "\n",
      "    User: Я нахожусь во Владивостоке и хочу поехать заграницу.\n",
      "Я думаю в Китай или в Европу, во Францию или Испанию, например.\n",
      "Как мне лучше это сделать?\n",
      "    AI: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''Я нахожусь во Владивостоке и хочу поехать заграницу.\n",
    "Я думаю в Китай или в Европу, во Францию или Испанию, например.\n",
    "Как мне лучше это сделать?'''\n",
    "print(dynamic_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ee164db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: О, Владивосток как база для мировых походов — романтично и немножко печально одновременно. Китай или Европа? Да начнём весёлый план, чтобы не промахнуться мимо виз и чемоданов.\n",
      "\n",
      "Как лучше сделать план быстро и без слёз:\n",
      "- Шаг 1. Выясни направление и города: Китай (Пекин/Шанхай) или Европа (Франция, Испания). Ещё можно смешать — но давайте по одному направлению, чтобы не путать визы.\n",
      "- Шаг 2. Визовый вопрос для граждан РФ:\n",
      "  - Китай: виза туристическая (L-виза). Можно подать через консульство/визовый центр. Есть вариант 144-часовой визы через конкретные города для транзита, но его условия требуют детального маршрута и третьей страны-пересечения. Гораздо чаще — обычная виза. Также есть можно рассмотреть визы типа Hainan visa-free, если планируете только поездку на Хайнань.\n",
      "  - Европа (Шенген): нужна шенгенская виза. Обычно минимум за 2–3 недели (а иногда и дольше). Нужны: анкета, паспорт, фото, страховка на 30k евро, бронь жилья/план поездки, финансовые документы, возможно приглашение.\n",
      "- Шаг 3. Подготовка документов:\n",
      "  - Загранпаспорт действителен минимум ещё 6 месяцев после планируемой даты возвращения.\n",
      "  - Бюджетная памятка: держи копии документов, запас копий на смартфоне, фото на случай.\n",
      "  - Подтверждения: билеты туда-обратно, жильё, страховка, маршрут по дням, доказательство финансов (выписка по счёту/карты).\n",
      "- Шаг 4. Бронирование и маршрутизация:\n",
      "  - Китай: ищи маршрут до города-короля перелётов (Пекин/Шанхай) через знакомые хабы; Европа: обычно через Москву, Стамбул или Доху — и дальше по Шенгену.\n",
      "  - Прямые варианты из Владивостока в Китай/Европу редко бывают постоянно, чаще требуется пересадка в Москве/Сеуле/Токио и т. д.\n",
      "- Шаг 5. Бюджет и страховка:\n",
      "  - Оцени стоимость визового сбора, билетов, проживания и питания в выбранной стране.\n",
      "  - Страховка на сумму не менее 30 000 евро (или эквивалент) — обязательно.\n",
      "- Шаг 6. Витамины от стресса визовых процедур:\n",
      "  - Собери пакет документов заранее, держи запас времени на обработку визы (минимум 2–3 недели, иногда больше).\n",
      "  - Если хочется минимизировать риски — можно обратиться к визовому агентству/туроператору.\n",
      "\n",
      "Совет по выбору: если цель — максимально безболезненно получить визу и планировать бюджет, Европа (Шенген) обычно требует больше подготовки, но даёт полезный опыт и множество красивых городов. Китай же проще оформить в некоторых случаях (особенно если есть маршрут через Хайнань или 144-часовой визовый режим), но потребует точного маршрута и документов.\n",
      "\n",
      "Хочешь, я помогу конкретно под твою ситуацию? скажи:\n",
      "- твоя гражданство/паспорт (для визы);\n",
      "- предполагаемые даты поездки;\n",
      "- город(а) в Китае или Европе, которые хочешь посетить;\n",
      "- ориентировочный бюджет;\n",
      "- планируешь ли 1-2 недель или дольше?\n",
      "\n",
      "Пока ты об этом думаешь, возьми кофе и помни: Владивосток — это не просто путь до моря, это путь до мира. Готов приступить к персонализированному плану под твои данные.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(dynamic_prompt_template.format(query=query)).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25d16170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\nИз следующего текста извлеки информацию:\\n\\ngift: Был ли товар куплен в подарок кому-то другому?\\nОтветь «True», если да, «False», если нет или неизвестно.\\n\\ndelivery_days: Сколько дней потребовалось для доставки товара? \\nЕсли эта информация не найдена, выведи -1.\\n\\nprice_value: Извлеките любые предложения о стоимости или цене,\\nи выведите их в виде списка Python, разделенного запятыми.\\n\\nОтформатируй вывод в формате JSON, используя следующие ключи:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "customer_review = \"\"\"\n",
    "Этот фен для волос просто потрясающий. Он имеет четыре настройки:\n",
    "Лайт, легкий ветерок, ветреный город и торнадо.\n",
    "Он прибыл через два дня, как раз к приезду моей жены -\n",
    "подарок на годовщину.\n",
    "Думаю, моей жене это настолько понравилось, что она потеряла дар речи.\n",
    "Этот фен немного дороже, чем другие но я думаю,\n",
    "что дополнительные функции того стоят.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\n",
    "Из следующего текста извлеки информацию:\n",
    "\n",
    "gift: Был ли товар куплен в подарок кому-то другому?\n",
    "Ответь «True», если да, «False», если нет или неизвестно.\n",
    "\n",
    "delivery_days: Сколько дней потребовалось для доставки товара? \n",
    "Если эта информация не найдена, выведи -1.\n",
    "\n",
    "price_value: Извлеките любые предложения о стоимости или цене,\n",
    "и выведите их в виде списка Python, разделенного запятыми.\n",
    "\n",
    "Отформатируй вывод в формате JSON, используя следующие ключи:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da75c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gift\": \"True\",\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": \"['Этот фен немного дороже, чем другие но я думаю, что дополнительные функции того стоят.']\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "782317d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc777a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='gift', description='Был ли товар куплен в подарок кому-то другому? Ответь «True», если да, «False», если нет или неизвестно.', type='string'), ResponseSchema(name='delivery_days', description='Сколько дней потребовалось для доставки товара? Если эта информация не найдена, выведи -1.', type='string'), ResponseSchema(name='price_value', description='Извлеките любые предложения о стоимости или цене, и выведите их в виде списка Python, разделенного запятыми.', type='string')])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "# Понадобится ещё одна сущность: схема ответа - ResponseSchema\n",
    "gift_schema = ResponseSchema(\n",
    "    name=\"gift\",\n",
    "    description=\"Был ли товар куплен в подарок кому-то другому? Ответь «True», если да, «False», если нет или неизвестно.\"\n",
    ")\n",
    "\n",
    "delivery_days_schema = ResponseSchema(\n",
    "    name=\"delivery_days\",\n",
    "    description=\"Сколько дней потребовалось для доставки товара? Если эта информация не найдена, выведи -1.\"\n",
    ")\n",
    "\n",
    "price_value_schema = ResponseSchema(\n",
    "    name=\"price_value\",\n",
    "    description=\"Извлеките любые предложения о стоимости или цене, и выведите их в виде списка Python, разделенного запятыми.\"\n",
    ")\n",
    "\n",
    "response_schemas = [\n",
    "    gift_schema, \n",
    "    delivery_days_schema,\n",
    "    price_value_schema\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "809e0537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Был ли товар куплен в подарок кому-то другому? Ответь «True», если да, «False», если нет или неизвестно.\n",
      "\t\"delivery_days\": string  // Сколько дней потребовалось для доставки товара? Если эта информация не найдена, выведи -1.\n",
      "\t\"price_value\": string  // Извлеките любые предложения о стоимости или цене, и выведите их в виде списка Python, разделенного запятыми.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78f29f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Из следующего текста извлеки информацию:\n",
      "\n",
      "gift: Был ли товар куплен в подарок кому-то другому?\n",
      "Ответь «True», если да, «False», если нет или неизвестно.\n",
      "\n",
      "delivery_days: Сколько дней потребовалось для доставки товара? \n",
      "Если эта информация не найдена, выведи -1.\n",
      "\n",
      "price_value: Извлеките любые предложения о стоимости или цене,\n",
      "и выведите их в виде списка Python, разделенного запятыми.\n",
      "\n",
      "text: \n",
      "Этот фен для волос просто потрясающий. Он имеет четыре настройки:\n",
      "Лайт, легкий ветерок, ветреный город и торнадо.\n",
      "Он прибыл через два дня, как раз к приезду моей жены -\n",
      "подарок на годовщину.\n",
      "Думаю, моей жене это настолько понравилось, что она потеряла дар речи.\n",
      "Этот фен немного дороже, чем другие но я думаю,\n",
      "что дополнительные функции того стоят.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Был ли товар куплен в подарок кому-то другому? Ответь «True», если да, «False», если нет или неизвестно.\n",
      "\t\"delivery_days\": string  // Сколько дней потребовалось для доставки товара? Если эта информация не найдена, выведи -1.\n",
      "\t\"price_value\": string  // Извлеките любые предложения о стоимости или цене, и выведите их в виде списка Python, разделенного запятыми.\n",
      "}\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "Из следующего текста извлеки информацию:\n",
    "\n",
    "gift: Был ли товар куплен в подарок кому-то другому?\n",
    "Ответь «True», если да, «False», если нет или неизвестно.\n",
    "\n",
    "delivery_days: Сколько дней потребовалось для доставки товара? \n",
    "Если эта информация не найдена, выведи -1.\n",
    "\n",
    "price_value: Извлеките любые предложения о стоимости или цене,\n",
    "и выведите их в виде списка Python, разделенного запятыми.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(\n",
    "    text=customer_review, \n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c0bf35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n\\t\"gift\": \"True\",\\n\\t\"delivery_days\": \"2\",\\n\\t\"price_value\": \"[\\'немного дороже, чем другие\\']\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1201, 'prompt_tokens': 332, 'total_tokens': 1533, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1152, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLpHYjU9srNtkmR51EMWbLR4HSUq2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--91086095-bea1-4b3c-8e03-442d356b86e9-0' usage_metadata={'input_tokens': 332, 'output_tokens': 1201, 'total_tokens': 1533, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1152}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03126ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': 'True',\n",
       " 'delivery_days': '2',\n",
       " 'price_value': \"['немного дороже, чем другие']\"}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict = output_parser.parse(response.content)\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44822d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-vectordb-Chhx0xS9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
