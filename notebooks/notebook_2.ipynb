{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c012e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amir/study/langchain_vectordb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amir/.cache/pypoetry/virtualenvs/langchain-vectordb-Chhx0xS9-py3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c055ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key: str = os.getenv(\"api_key\", \"\")\n",
    "base_url: str = os.getenv(\"base_url\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11921ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-nano-2025-08-07\",\n",
    "    api_key=api_key,\n",
    "    base_url=base_url,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d9997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Ты полезный AI-ассистент с чувством юмора.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Расскажи мне шутку на тему - космос', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"Ты полезный AI-ассистент с чувством юмора.\"),\n",
    "    (\"user\", \"Расскажи мне шутку на тему - {topic}\"),\n",
    "])\n",
    "prompt_template.invoke({\"topic\": \"космос\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3c6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Перепиши этот текcт в заданном стиле: {input_text}\n",
    "Стиль: {style}.\n",
    "Результат:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text', 'style'],\n",
    "    template=template \n",
    ")\n",
    "style_changer_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c03bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Приветствую вас, досточтимые читатели, на курсе по тюнингу языковых моделей. Здесь мы учимся придать моделям речевым ещё более благородный облик и раскрыть до предела их скрытый потенциал; предлагаем советы по самым свежим методам обучения и настройки этих умных машин, и воспитаем вместе практические умения, необходимые для решения самых сложных задач в деле обработки естественного языка.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 2153, 'prompt_tokens': 113, 'total_tokens': 2266, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2048, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLtfgysqocamPKMTt7RCQDgMA5YEN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--080c4f0d-accd-4d73-87ad-512cbd3c211f-0' usage_metadata={'input_tokens': 113, 'output_tokens': 2153, 'total_tokens': 2266, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 2048}}\n"
     ]
    }
   ],
   "source": [
    "text = '''Приветствуем на курсе по тюнингу языковых моделей! \n",
    "Тут мы учим, как сделать модельки еще круче и раскрыть их потенциал до максимума. \n",
    "Мы дадим вам советы по самым свежим методам обучения и настройки языковых моделей, \n",
    "а также научим практическим навыкам для решения сложных задач в обработке естественного языка.'''\n",
    "style = 'Роман 18 века'\n",
    "\n",
    "answer = style_changer_chain.invoke({'input_text': text, 'style': style})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2e7968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приветствую вас, досточтимые читатели, на курсе по тюнингу языковых моделей. Здесь мы учимся придать моделям речевым ещё более благородный облик и раскрыть до предела их скрытый потенциал; предлагаем советы по самым свежим методам обучения и настройки этих умных машин, и воспитаем вместе практические умения, необходимые для решения самых сложных задач в деле обработки естественного языка.\n"
     ]
    }
   ],
   "source": [
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "733da0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_answer = style_changer_chain.batch([\n",
    "    {'input_text': text, 'style': 'В стиле времен советского союза 1950 гг'},\n",
    "    {'input_text': text, 'style': 'В стиле поэмы'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de3257c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Товарищи! Добро пожаловать на курс по тюнингу языковых моделей. Здесь мы учимся превращать модели в ещё более мощные и крепкие инструменты, раскрывая их потенциал до предела возможностей науки и техники. Мы дадим вам советы по передовым методам обучения и настройки языковых моделей, а также обучим практическим навыкам для решения самых сложных задач в области обработки естественного языка. Да здравствует научный труд, да здравствует прогресс и победы техники!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_answer[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a252cf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добро пожаловать на курс по тюнингу языковых моделей,\n",
      "где слова и коды сплетаются в новый гимн данных.\n",
      "Мы учим вас делать модели ещё круче,\n",
      "раскрывать их потенциал до максимума — без границ.\n",
      "\n",
      "Мы дадим советы по самым свежим методам обучения\n",
      "и тонкой настройке языковых моделей,\n",
      "а также научим практическим навыкам для решения\n",
      "сложнейших задач в обработке естественного языка.\n",
      "\n",
      "Пусть этот путь звучит стихами алгоритмов,\n",
      "пусть каждая идея загорается искрой новых трактовок,\n",
      "и ваш опыт растёт — шаг за шагом к вершинам понимания.\n"
     ]
    }
   ],
   "source": [
    "print(batch_answer[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a92479c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добро пожаловать в курс тюнинга языковых моделей,\n",
      "где шепчет нейронный океан и искрят строки данных.\n",
      "Мы учим: как сделать модели ещё круче,\n",
      "как раскрыть их потенциал до максимума — без границ и стен.\n",
      "\n",
      "Мы принесём советы по самым свежим методам обучения и настройки,\n",
      "как ветер—между слоями и параметрами лёгко проскользнуть.\n",
      "И научим практическим навыкам для решения задач,\n",
      "что в обработке естественного языка стоят над веками вопросов.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "chain_with_parser = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain_with_parser.invoke({'input_text': text, 'style': 'В стиле поэмы'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7273011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приветствуем на курсе по тюнингу языковых моделей! \n",
      "Тут мы учим, как сделать модельки еще круче и раскрыть их потенциал до максимума. \n",
      "Мы дадим вам советы по самым свежим методам обучения и настройки языковых моделей,\n",
      "а также научим практическим навыкам для решения сложных задач в обработке естественного языка.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def del_spaces(inputs: dict) -> dict:\n",
    "    text = inputs[\"input_text\"]\n",
    "    style = inputs[\"style\"]\n",
    "    \n",
    "    # заменяем пустые строки и дополнительные пробелы на один, используя регулярные выражения\n",
    "    text = re.sub(r'(\\r\\n|\\r|\\n){2,}', r'\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "    return {\"input_text\": text, 'style': style}\n",
    "\n",
    "dirty_text = '''Приветствуем на курсе по        тюнингу языковых        моделей! \n",
    "\n",
    "Тут мы учим, как сделать модельки еще круче и раскрыть     их потенциал до максимума. \n",
    "Мы дадим вам советы по   самым свежим методам  обучения и настройки языковых                    моделей,\n",
    "\n",
    "а также научим практическим навыкам для        решения сложных задач в обработке естественного языка.'''\n",
    "\n",
    "print(del_spaces({'input_text': dirty_text, 'style': 'Рэп'})['input_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0193190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат:\n",
      "Йо, привет на курсе тюнинга языковых моделей,\n",
      "Здесь поднимаем их крутизну и раскрываем потенциал до максимума.\n",
      "Мы учим, как сделать модельки ещё круче и зажечь их внутри,\n",
      "Прокачаем гиперпараметры и методы обучения — без пауз и суеты внутри.\n",
      "Дадим вам свежайшие советы по настройке и архитектуре,\n",
      "И на практике научим решать НЛП-задачи — чётко, быстро, без мути и фигуры.\n",
      "Код на битах, пайплайны в ритме — движемся вперёд без промаха,\n",
      "Этот рэп-курс — место, где наука встречается с стилем и движухой.\n"
     ]
    }
   ],
   "source": [
    "seq_chain = del_spaces | prompt | llm |  StrOutputParser() # Готово!!!\n",
    "print(seq_chain.invoke({'input_text': dirty_text, 'style': 'Рэп'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d361eef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encuentra en Italia.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_1 = ChatPromptTemplate.from_template(\"В каком городе родился {person}?\")\n",
    "prompt_2 = ChatPromptTemplate.from_template(\"В какой стране находится город {city}? Ответь на {language} языке.\")\n",
    "\n",
    "chain_1 = prompt_1 | llm | StrOutputParser()\n",
    "chain_2 = (\n",
    "    {\"city\": chain_1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt_2 \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "result = chain_2.invoke({\"person\": \"Колумб\", \"language\": \"испанском\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9fb1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain.schema.runnable import RunnableBranch, RunnablePassthrough\n",
    "from langchain.output_parsers.openai_functions import PydanticAttrOutputFunctionsParser\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0baa6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "botanist_template = \"\"\"Ты очень опытный флорист и ботаник, знаешь всё о цветах, растениях.\n",
    "Тебе нравится отвечать на вопросы о том, как выбирать и ухаживать за растениями. \n",
    "Ты отвечаешь так, что всё становится ясно даже начинающему цветоводу. \n",
    "Вот вопрос:\n",
    "{input}\"\"\"\n",
    "\n",
    "football_template = \"\"\"Ты спортивный журналист с большим опытом, твоя основная специализация футбол.\n",
    "Ты знаешь всё о футбольных командах и игроках, и очень любишь отвечать на вопросы о футболе, но кратко и по делу.\n",
    "Вот вопрос:\n",
    "{input}\"\"\"\n",
    "\n",
    "botanist_prompt = PromptTemplate.from_template(botanist_template)\n",
    "football_prompt = PromptTemplate.from_template(football_template)\n",
    "\n",
    "# Создаём ветки\n",
    "prompt_branch = RunnableBranch(\n",
    "    (lambda x: x[\"topic\"] == \"botany\", botanist_prompt),\n",
    "    (lambda x: x[\"topic\"] == \"football\", football_prompt),\n",
    "    PromptTemplate.from_template(\"Answer the question: {input}\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5801927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicClassifier(BaseModel):\n",
    "    \"Classify the topic of the user question\"\n",
    "    topic: Literal[\"botany\", \"football\", \"general\"]\n",
    "    \n",
    "    \n",
    "classifier_function = convert_to_openai_function(TopicClassifier)\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url,\n",
    "    model='gpt-5-nano-2025-08-07', \n",
    "    ).bind(\n",
    "        functions=[classifier_function],\n",
    "        function_call={\"name\": \"TopicClassifier\"}\n",
    "    )\n",
    "parser = PydanticAttrOutputFunctionsParser(pydantic_schema=TopicClassifier, attr_name=\"topic\")\n",
    "\n",
    "classifier_chain = model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a9867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-vectordb-Chhx0xS9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
